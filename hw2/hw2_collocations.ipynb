{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2_collocations",
      "provenance": [],
      "authorship_tag": "ABX9TyNCKkrSsHxYcEf6ZY9nFcf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ovbystrova/hse_compling/blob/main/hw2/hw2_collocations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9WIjC1Q1tYw"
      },
      "source": [
        "# Imports and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7yeEnlo2e2t"
      },
      "source": [
        "%%capture\n",
        "!pip install razdel"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK-kyo2xzAGN"
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/2ch_corpus.txt.zip  -O dvach_corpus.txt.zip\n",
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/lenta.txt.zip -O lenta.txt.zip\n",
        "\n",
        "!unzip dvach_corpus.txt.zip\n",
        "!unzip lenta.txt.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaQvTC7as6w2",
        "outputId": "acc85bb5-8061-47fe-abed-94c10a482413"
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from string import punctuation\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfJU8g-J0ms1"
      },
      "source": [
        "fname_lenta = 'lenta.txt'\n",
        "fname_2ch = '2ch_corpus.txt'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuD2mnxw0_rJ"
      },
      "source": [
        "with open(fname_lenta, 'r', encoding='utf-8') as f:\n",
        "    text_lenta = f.read()\n",
        "\n",
        "with open(fname_2ch, 'r', encoding='utf-8') as f:\n",
        "    text_2ch = f.read()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSFOdkp21M15",
        "outputId": "115b091e-443a-49dd-8dca-edf0e3dc6af2"
      },
      "source": [
        "len(text_lenta), text_lenta[:100]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11536552,\n",
              " 'Бои у Сопоцкина и Друскеник закончились отступлением германцев. Неприятель, приблизившись с севера к')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr119ZiP1OJx",
        "outputId": "e95f10e9-e771-4dbf-ddd7-9eccb55d0a23"
      },
      "source": [
        "len(text_2ch), text_2ch[:100]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11638405,\n",
              " ' Анимублядский WebM-треддля приличных анимублядей и прочих аутистов. Безграмотное быдло с дубляжом, ')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsqgBofsclq4"
      },
      "source": [
        "# Сокращаю размеры текстов, чтобы уместить в память\n",
        "text_lenta = text_lenta[:100000]\n",
        "text_2ch = text_2ch[:100000]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6a5n6QR1pBz"
      },
      "source": [
        "# Задание 1. (5 баллов) \n",
        "В тетрадке реализована биграмная языковая модель (при генерации учитывается информация только о 1 предыдущем слове). Реализуйте триграмную модель и сгенерируйте несколько текстов. Сравните их с текстами, сгенерированными биграмной моделью. \n",
        "Можно использовать те же тексты, что в семинаре, или взять какой-то другой (на английском или русском языке)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh8r8Fdh2naB"
      },
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text\n",
        "\n",
        "def ngrammer(tokens, n=3):\n",
        "    \"\"\"\n",
        "    Get ngrams from list of tokens\n",
        "    \"\"\"\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "\n",
        "def create_ngrams(sentences):\n",
        "    \"\"\"\n",
        "    Create unigrams, bigrams and trigrams from list of sentences\n",
        "    \"\"\"\n",
        "    unigrams, bigrams, trigrams = Counter(), Counter(), Counter()\n",
        "    for sentence in sentences:\n",
        "        unigrams.update(sentence)\n",
        "        bigrams.update(ngrammer(sentence, n=2))\n",
        "        trigrams.update(ngrammer(sentence, n=3))\n",
        "    return unigrams, bigrams, trigrams"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZmk6h8M1VUp"
      },
      "source": [
        "sentences_dvach = [ ['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(text_2ch)]\n",
        "sentences_news = [ ['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(text_lenta)]\n",
        "\n",
        "unigrams_dvach, bigrams_dvach, trigrams_dvach = create_ngrams(sentences_dvach)\n",
        "unigrams_news, bigrams_news, trigrams_news = create_ngrams(sentences_news)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJqw936JuhAo"
      },
      "source": [
        "def create_matrix(unigrams, bigrams, trigrams):\n",
        "    \"\"\"\n",
        "    Based on unigrams, bigrams and trigrams this function creates matrix of trigrams, bigrams and supporting indexes\n",
        "    \"\"\"\n",
        "    \n",
        "    matrix_trigrams = np.zeros((len(bigrams), len(unigrams)))\n",
        "    matrix_bigrams = np.zeros((len(unigrams), len(unigrams)))\n",
        "\n",
        "    print(\"Initialized matrix\")\n",
        "    id2bigram = list(bigrams)\n",
        "    bigram2id  =  {bigram:i for i, bigram in enumerate(id2bigram)}\n",
        "    id2word = list(unigrams)\n",
        "    word2id = {word:i for i, word in enumerate(id2word)}\n",
        "\n",
        "    print('Start to fill the matrix_trigrams')\n",
        "    for ngram in trigrams:\n",
        "        ngram_ = ngram.split(' ')\n",
        "        bigram, unigram = ' '.join(ngram_[:-1]), ngram_[-1]\n",
        "        matrix_trigrams[bigram2id[bigram]][word2id[unigram]] =  (trigrams[ngram] / bigrams[bigram])\n",
        "    print('Matrix is filled')\n",
        "\n",
        "    print('Start to fill the matrix_bigrams')\n",
        "    for ngram in bigrams:\n",
        "        word1, word2 = ngram.split(' ')\n",
        "        matrix_bigrams[word2id[word1]][word2id[word2]] =  (bigrams[ngram] / unigrams[word1])\n",
        "    print('Matrix is filled')\n",
        "    \n",
        "    return matrix_trigrams, matrix_bigrams, id2bigram, bigram2id, id2word, word2id "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7rde0O_wYhN",
        "outputId": "359033ca-614f-41a5-c86a-077190915230"
      },
      "source": [
        "matrix_trigrams_dvach, matrix_bigrams_dvach, id2bigram_dvach, bigram2id_dvach, id2word_dvach, word2id_dvach = create_matrix(unigrams_dvach, bigrams_dvach, trigrams_dvach)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized matrix\n",
            "Start to fill the matrix_trigrams\n",
            "Matrix is filled\n",
            "Start to fill the matrix_bigrams\n",
            "Matrix is filled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcz6v6l4xec2",
        "outputId": "d452e870-3c52-4b7b-d3da-5cc84e7362f1"
      },
      "source": [
        "matrix_trigrams_news, matrix_bigrams_news, id2bigram_news, bigram2id_news, id2word_news, word2id_news = create_matrix(unigrams_news, bigrams_news, trigrams_news)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized matrix\n",
            "Start to fill the matrix_trigrams\n",
            "Matrix is filled\n",
            "Start to fill the matrix_bigrams\n",
            "Matrix is filled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbrqOOCmQsyA"
      },
      "source": [
        "def generate_bigrams(matrix, id2word, word2id, n=100, start='<start>'):\n",
        "    \"\"\"\n",
        "    Text generation based on bigrams matrix\n",
        "    \"\"\"\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "            chosen = word2id[start]\n",
        "        current_idx = chosen\n",
        "    \n",
        "    return ' '.join(text)\n",
        "\n",
        "\n",
        "def generate_trigrams(matrix, id2word, ngram2id, id2ngram, n=100, start='<start> <start>'):\n",
        "    \"\"\"\n",
        "    Text generation based on trigrams matrix\n",
        "    \"\"\"\n",
        "    text = []\n",
        "    current_idx = ngram2id[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "            token = start\n",
        "        else:\n",
        "            token = id2ngram[current_idx].split()[-1] + \" \" + id2word[chosen]\n",
        "        current_idx = ngram2id[token]\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee8MTKjwz8MZ"
      },
      "source": [
        "def compare(matrix_bigrams, matrix_trigrams, id2word, word2id, bigram2id, id2bigram, n=100):\n",
        "    \"\"\"\n",
        "    Compare bigrams and trigrams texts\n",
        "    \"\"\"\n",
        "    print('====================Bigram Texts ==============================')\n",
        "    print(generate_bigrams(matrix=matrix_bigrams, id2word=id2word, word2id=word2id).replace('<end>', '\\n'))\n",
        "    print()\n",
        "    \n",
        "    print('====================Trigram Texts ==============================')\n",
        "    print(generate_trigrams(matrix=matrix_trigrams, id2word=id2word, ngram2id=bigram2id, id2ngram=id2bigram).replace('<end>', '\\n'))    \n",
        "    print() "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sFGfMdw1UCt",
        "outputId": "0ad9e4ca-4b32-478c-eef9-4f38a6d326dc"
      },
      "source": [
        "# Сравниваем Двач\n",
        "compare(matrix_bigrams_dvach, matrix_trigrams_dvach, id2word_dvach, word2id_dvach, bigram2id_dvach, id2bigram_dvach)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================Bigram Texts ==============================\n",
            "<start> <start> марксизм сталинизм \n",
            " <start> <start> <start> <start> глянь автора artofeel \n",
            " <start> с западными заказчиками со своим пофигизмом \n",
            " ещё что-нибудь умное спиздани и настройке кодеков на танцы всем рекомендую \n",
            " <start> табита кстати топ-20 отличная таблица выбора языка для работы кроме тебя подменю и стараются создать максимум 28 и бог с кем попиздеть \n",
            " они разговариваат о чем mit дауны сидят и понял \n",
            " <start> <start> <start> давай я понял \n",
            " хоть историю гугла чтоле лол бля соус музыки \n",
            " <start> <start> у вас вобьют хотя и все 28 какой-то \n",
            " предлагаю скидывать сюда всякие цуиь и\n",
            "\n",
            "====================Trigram Texts ==============================\n",
            "а теперь последний вопрос \n",
            " у них коэффициент интеллекта iq 180 знаете я расскажу одну историю \n",
            " так как они юрисношаются \n",
            " яндекс 41001634460485 похуй он пустой wmrr 944125761655 wm фейкижду с того что теперь бакалавриат а не писать об этом \n",
            " я никогда особо не был таким но потом что то переклинуло \n",
            " аниме унылое однообразное говно как диды большой ложкой как все меня учили и ты уже потёк из треда \n",
            " они же вместе телеграм сделали дауняра вслушайся в текст \n",
            " особенно в ранобце \n",
            " как продвигается с проектом \n",
            " обычная милашка секс-символ уровня it уцепившаяся в модный\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvDzdG6h7YCr",
        "outputId": "24e8d2b5-0d2d-4039-cc3b-6adc11d467f3"
      },
      "source": [
        "# Сравниваем Новости\n",
        "compare(matrix_bigrams_news, matrix_trigrams_news, id2word_news, word2id_news, bigram2id_news, id2bigram_news)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================Bigram Texts ==============================\n",
            "<start> но с орбиты и автомобили \n",
            " в операциях проводимых через лес до 140 тысячлет \n",
            " королевская семья отметит траурную годовщину церемонией в 21 человека госпитализировано \n",
            " <start> новый повод для того как утверждает intel их абазинский черкесский и удерживающими 12 заложников освобождены минувшей ночью на пресечение попыток привнесения элементов политического экстремизма а сразу на манежной площади не пострадали \n",
            " <start> <start> <start> новое расследование \n",
            " <start> все от залива ла-плата \n",
            " сегодня была одобрена советом руководителей таможенных пунктах на повестке дня рождения м ю \n",
            " <start> <start> <start> <start> <start> как указывается в убежище сектантов во всех избирателей \n",
            "\n",
            "\n",
            "====================Trigram Texts ==============================\n",
            "однако число пострадавших в результате этого взрыва может составить до ста человек \n",
            " при продолжающемся отступлении австрийцев обнаруживается полное перемешивание их частей захватываются новые партии пленных орудия и прочая материальная часть \n",
            " с этого момента бульдог стал настоящим гонцом \n",
            " колокола освятили и скоро вновь подвесят на колокольню \n",
            " мы приводим полный перевод статьи опубликованнойв газете сегодня \n",
            " в настоящее время в стационарах и больницах города находится 24 раненых 9 из них в критическом состоянии у троих обожжено до 50 процентов кожи \n",
            " лидер курдов абдулла оджалан в июне был приговорен к смерти судом турции \n",
            " у одного мужчины обожжено\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jesc6po7g4P"
      },
      "source": [
        "В обоих текстах очевидно, что с помощью триграммной матрицы генерируются более осмысленные тексты (как синтаксически, так и семантически). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D1WVwjoojYa"
      },
      "source": [
        "# Задание 2. (5 баллов) \n",
        "Напишите функцию оценивания нграммов на основе PMI. Используйте эту функцию вместо дефолтной в gensim.models.Phrases Обучите два последовательных модели Phrases с такой функцией и проанализируйте результаты, получаемые после преобразования текстов двумя Phrases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ccFLjQToxJE"
      },
      "source": [
        "Пояснения:\n",
        "Формулу PMI можно посмотреть вот тут https://en.wikipedia.org/wiki/Pointwise_mutual_information , также там описано как вывести вероятности из количества вхождений слова1, слова2, нграмма и размера корпуса.\n",
        "Чтобы функцию можно было поставить в аргумент scoring в Phrases у нее должны быть вот такие аргументы - scorer(worda_count, wordb_count, bigram_count, len_vocab, min_count, corpus_word_count) \n",
        "Подберите параметр threshold под эту функцию. Чтобы проверить, что она вообще работает поставьте какое-то совсем маленькое число, чтобы порог проходили все нграммы и потом постепенно его повышайте.\n",
        "В тетрадке есть пример обучения нескольких Phrases последовательно, воспользуйтесь им."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-pJw9vyc5NT"
      },
      "source": [
        "# https://github.com/RaRe-Technologies/gensim/blob/1d0a8bddc04090d07f55b8830ba451789b3fb7d0/gensim/models/phrases.py \n",
        "# Тут за основу взят normalized pmi из генсима\n",
        "\n",
        "def pmi_score(worda_count, wordb_count, bigram_count, len_vocab, min_count, corpus_word_count):\n",
        "    if bigram_count >= min_count:\n",
        "        try:\n",
        "            prob_a = worda_count / corpus_word_count\n",
        "            prob_b = wordb_count / corpus_word_count\n",
        "            prob_ab = bigram_count / corpus_word_count\n",
        "            pmi = np.log(prob_ab / (prob_a * prob_b))\n",
        "        except ZeroDivisionError:\n",
        "            pmi = float('-inf') \n",
        "    else:\n",
        "        pmi = float('-inf') \n",
        "    return pmi"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QExJ3GZv_O9O",
        "outputId": "def00713-0b21-4efc-c9af-4741f7fc0076"
      },
      "source": [
        "pmi_score(10, 11, 9, 5, 0, 2000000), pmi_score(10, 11, 9, 5, 0, 200)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12.005401950068022, 2.7950615780918397)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RyEbidDMs2A"
      },
      "source": [
        "with open(fname_lenta, 'r', encoding='utf-8') as f:\n",
        "    text_lenta = f.read()\n",
        "\n",
        "with open(fname_2ch, 'r', encoding='utf-8') as f:\n",
        "    text_2ch = f.read()\n",
        "    \n",
        "sentences_dvach = [normalize(text)for text in sent_tokenize(text_2ch)]\n",
        "sentences_news = [normalize(text)for text in sent_tokenize(text_lenta)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krVtG8SkBqyT",
        "outputId": "8ff23e78-3b43-4495-9655-2e5e44ec30c1"
      },
      "source": [
        "# default scoring\n",
        "ph_default = gensim.models.Phrases(sentences_dvach, threshold=0.0001)\n",
        "p_default = gensim.models.phrases.Phraser(ph_default)\n",
        "\n",
        "# собираем статистики по уже забиграммленному тексту\n",
        "ph2_default = gensim.models.Phrases(p_default[sentences_dvach])\n",
        "p2_default = gensim.models.phrases.Phraser(ph2_default)\n",
        "for i in  [50, 29, 23, 566, 491, 94, 222]:\n",
        "    print(p2_default[p_default[sentences_dvach[i]]])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['вы', 'ничего_не', 'понимаете', 'в', 'настоящей', 'игре', 'что_значит', 'например_где']\n",
            "['вчера', 'этой', 'не_было', 'пришлось', 'самому', 'резать']\n",
            "['дропнул', 'из-за', 'ссыкухи']\n",
            "['рады', 'чистить', 'ваши', 'конюшни', 'сэр']\n",
            "['хардкор']\n",
            "['так_что', 'я_за', 'ту', 'с', 'непроизносимым', 'именем', 'в_15', 'слов']\n",
            "['рисовка', 'как_у', 'дитей', 'даунов_в', '5_лет', 'это', 'оригинал', 'манги', 'ванпанчмена']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kJzgnZUCQXY",
        "outputId": "4e843b83-bf92-4dec-bf7d-fe6094eadb29"
      },
      "source": [
        "# Наш PMI\n",
        "ph_custom = gensim.models.Phrases(sentences_dvach, scoring=pmi_score, threshold=0.0001)\n",
        "p_custom = gensim.models.phrases.Phraser(ph_custom)\n",
        "\n",
        "# собираем статистики по уже забиграммленному тексту\n",
        "ph2_custom = gensim.models.Phrases(p_custom[sentences_dvach], scoring=pmi_score)\n",
        "p2_custom = gensim.models.phrases.Phraser(ph2_custom)\n",
        "for i in  [50, 29, 23, 566, 491, 94, 222]:\n",
        "    print(p2_custom[p_custom[sentences_dvach[i]]])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['вы_ничего', 'не_понимаете', 'в', 'настоящей', 'игре', 'что_значит', 'например_где']\n",
            "['вчера', 'этой', 'не_было', 'пришлось', 'самому', 'резать']\n",
            "['дропнул', 'из-за', 'ссыкухи']\n",
            "['рады', 'чистить', 'ваши', 'конюшни', 'сэр']\n",
            "['хардкор']\n",
            "['так_что', 'я', 'за_ту', 'с', 'непроизносимым', 'именем', 'в_15', 'слов']\n",
            "['рисовка', 'как_у', 'дитей', 'даунов_в', '5_лет', 'это', 'оригинал', 'манги', 'ванпанчмена']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTrg0u_UL-_U",
        "outputId": "ffdba0c2-9989-4142-ffaa-3f5ed5983d7a"
      },
      "source": [
        "ph_default = gensim.models.Phrases(sentences_dvach, threshold=13)\n",
        "p_default = gensim.models.phrases.Phraser(ph_default)\n",
        "\n",
        "# собираем статистики по уже забиграммленному тексту\n",
        "ph2_default = gensim.models.Phrases(p_default[sentences_dvach])\n",
        "p2_default = gensim.models.phrases.Phraser(ph2_default)\n",
        "for i in  [50, 29, 23, 566, 491, 94, 222]:\n",
        "    print(p2_default[p_default[sentences_dvach[i]]])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['вы', 'ничего_не', 'понимаете', 'в', 'настоящей', 'игре', 'что', 'значит', 'например', 'где']\n",
            "['вчера', 'этой', 'не', 'было', 'пришлось', 'самому', 'резать']\n",
            "['дропнул', 'из-за', 'ссыкухи']\n",
            "['рады', 'чистить', 'ваши', 'конюшни', 'сэр']\n",
            "['хардкор']\n",
            "['так', 'что', 'я', 'за', 'ту', 'с', 'непроизносимым', 'именем', 'в', '15', 'слов']\n",
            "['рисовка', 'как', 'у', 'дитей', 'даунов', 'в', '5_лет', 'это', 'оригинал', 'манги', 'ванпанчмена']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZI8up_OMFi1",
        "outputId": "cd4ff718-acd8-4480-bbe1-f3ae868c84a3"
      },
      "source": [
        "# Наш PMI\n",
        "ph_custom = gensim.models.Phrases(sentences_dvach, scoring=pmi_score, threshold=13)\n",
        "p_custom = gensim.models.phrases.Phraser(ph_custom)\n",
        "\n",
        "# собираем статистики по уже забиграммленному тексту\n",
        "ph2_custom = gensim.models.Phrases(p_custom[sentences_dvach], scoring=pmi_score)\n",
        "p2_custom = gensim.models.phrases.Phraser(ph2_custom)\n",
        "for i in  [50, 29, 23, 566, 491, 94, 222]:\n",
        "    print(p2_custom[p_custom[sentences_dvach[i]]])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['вы', 'ничего', 'не', 'понимаете', 'в', 'настоящей', 'игре', 'что', 'значит', 'например', 'где']\n",
            "['вчера', 'этой', 'не', 'было', 'пришлось', 'самому', 'резать']\n",
            "['дропнул', 'из-за', 'ссыкухи']\n",
            "['рады', 'чистить', 'ваши', 'конюшни', 'сэр']\n",
            "['хардкор']\n",
            "['так', 'что', 'я', 'за', 'ту', 'с', 'непроизносимым', 'именем', 'в', '15', 'слов']\n",
            "['рисовка', 'как', 'у', 'дитей', 'даунов', 'в', '5', 'лет', 'это', 'оригинал', 'манги', 'ванпанчмена']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcGrprq_uP0S"
      },
      "source": [
        "В данном пункте я взяла только тексты двача. Можем также заметить, что дефолтный scoring показывает лучше результаты, чем наш pmi с обеими версиями threshold'а. Наш pmi не выделает нграмы если мы повышаем порог."
      ]
    }
  ]
}