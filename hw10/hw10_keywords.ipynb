{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW10_Nefedov.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zV3YMZ72JuF-",
        "vl50D0jIKG_n",
        "sqWL43N3LSz6",
        "78Rlh9wD6YXv",
        "ekXHM_cjjZNm"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV3YMZ72JuF-"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1rzAxKgH1JI"
      },
      "source": [
        "%%capture\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/ng_0.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/ng_1.jsonlines.zip\n",
        "\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/cyberleninka_0.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/cyberleninka_1.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/cyberleninka_2.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/cyberleninka_3.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/cyberleninka_4.jsonlines.zip\n",
        "\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/habrahabr_0.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/habrahabr_1.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/habrahabr_2.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/habrahabr_3.jsonlines.zip\n",
        "\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/russia_today_0.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/russia_today_1.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/russia_today_2.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/russia_today_3.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/russia_today_4.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/russia_today_5.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/russia_today_6.jsonlines.zip\n",
        "!wget https://github.com/mannefedov/ru_kw_eval_datasets/raw/master/data/russia_today_7.jsonlines.zip\n",
        "\n",
        "!unzip ng_0.jsonlines.zip \n",
        "!unzip ng_1.jsonlines.zip\n",
        "\n",
        "!unzip cyberleninka_0.jsonlines.zip\n",
        "!unzip cyberleninka_1.jsonlines.zip\n",
        "!unzip cyberleninka_2.jsonlines.zip\n",
        "!unzip cyberleninka_3.jsonlines.zip\n",
        "!unzip cyberleninka_4.jsonlines.zip\n",
        "\n",
        "!unzip habrahabr_0.jsonlines.zip\n",
        "!unzip habrahabr_1.jsonlines.zip\n",
        "!unzip habrahabr_2.jsonlines.zip\n",
        "!unzip habrahabr_3.jsonlines.zip\n",
        "\n",
        "!unizp russia_today_0.jsonlines.zip\n",
        "!unizp russia_today_1.jsonlines.zip\n",
        "!unizp russia_today_2.jsonlines.zip\n",
        "!unizp russia_today_3.jsonlines.zip\n",
        "!unizp russia_today_4.jsonlines.zip\n",
        "!unizp russia_today_5.jsonlines.zip\n",
        "!unizp russia_today_6.jsonlines.zip\n",
        "!unizp russia_today_7.jsonlines.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl50D0jIKG_n"
      },
      "source": [
        "# Main Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p74jyf-RKIuv"
      },
      "source": [
        "Всю загрузку данных я убрала, но по размеру датасета видно, что использовались все данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8OKLWz5MHA5",
        "outputId": "b8db5356-319a-4bf7-f97c-236e9c287e42"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehF2BgYyIsbW",
        "outputId": "ef715774-5088-4016-84ef-831bd33295f3"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "\n",
        "from gensim import summarization\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "stops = set(stopwords.words('russian'))\n",
        "punct = punctuation+'«»—…“”*№–'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "nScqKrWRIYic",
        "outputId": "c0792dbf-f5fe-4cb8-ef3f-3a79a45e4967"
      },
      "source": [
        "PATH_TO_DATA = './'\n",
        "files = [os.path.join(PATH_TO_DATA, file) for file in os.listdir(PATH_TO_DATA) if file.endswith('jsonlines')]\n",
        "print(f\"There are {len(files)} files\")\n",
        "\n",
        "data = pd.concat([pd.read_json(file, lines=True) for file in files], axis=0, ignore_index=True)\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 11 files\n",
            "(10049, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>url</th>\n",
              "      <th>keywords</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MassTransit это open source библиотека, разра...</td>\n",
              "      <td>Опыт использования MassTransit 3.0</td>\n",
              "      <td>MassTransit это open source библиотека, разраб...</td>\n",
              "      <td>https://habrahabr.ru/post/314080/</td>\n",
              "      <td>[.net, rabbitmq, masstransit]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Введение и выбор решения \\r\\nРано или поздно ...</td>\n",
              "      <td>Геймификация форума на движке XenForo</td>\n",
              "      <td>Введение и выбор решения\\r\\nРано или поздно н...</td>\n",
              "      <td>https://habrahabr.ru/company/plesk/blog/313732/</td>\n",
              "      <td>[геймификация, xenforo, форумные движки, форум...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\r\\nНа сегодняшний день процедура реализации ...</td>\n",
              "      <td>Кластер высокой доступности на postgresql 9.6 ...</td>\n",
              "      <td>\\r\\nНа сегодняшний день процедура реализации «...</td>\n",
              "      <td>https://habrahabr.ru/company/etagi/blog/314000/</td>\n",
              "      <td>[postgresq, haproxy, pgbouncer, keepalived, re...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Как часто, программируя очередную бизнес-фичу,...</td>\n",
              "      <td>Как перестать бояться и полюбить синтаксически...</td>\n",
              "      <td>Как часто, программируя очередную бизнес-фичу,...</td>\n",
              "      <td>https://habrahabr.ru/company/knopka/blog/314030/</td>\n",
              "      <td>[irony, .net, c#, грамматический разбор, синта...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Индустрия звука, о которая была у всех на слух...</td>\n",
              "      <td>Мифы и реальность: Что нужно знать о современн...</td>\n",
              "      <td>Индустрия звука, о которая была у всех на слух...</td>\n",
              "      <td>https://geektimes.ru/company/audiomania/blog/2...</td>\n",
              "      <td>[аудиомания, мифы и реальность, акустика, ауди...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ... abstract\n",
              "0   MassTransit это open source библиотека, разра...  ...      NaN\n",
              "1   Введение и выбор решения \\r\\nРано или поздно ...  ...      NaN\n",
              "2   \\r\\nНа сегодняшний день процедура реализации ...  ...      NaN\n",
              "3  Как часто, программируя очередную бизнес-фичу,...  ...      NaN\n",
              "4  Индустрия звука, о которая была у всех на слух...  ...      NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "pabjFDohIwel",
        "outputId": "35df23fa-9629-4538-cf43-3460e0bdd922"
      },
      "source": [
        "data['keywords'] = data['keywords'].apply(lambda x: [el.lower() for el in x])\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>url</th>\n",
              "      <th>keywords</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MassTransit это open source библиотека, разра...</td>\n",
              "      <td>Опыт использования MassTransit 3.0</td>\n",
              "      <td>MassTransit это open source библиотека, разраб...</td>\n",
              "      <td>https://habrahabr.ru/post/314080/</td>\n",
              "      <td>[.net, rabbitmq, masstransit]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Введение и выбор решения \\r\\nРано или поздно ...</td>\n",
              "      <td>Геймификация форума на движке XenForo</td>\n",
              "      <td>Введение и выбор решения\\r\\nРано или поздно н...</td>\n",
              "      <td>https://habrahabr.ru/company/plesk/blog/313732/</td>\n",
              "      <td>[геймификация, xenforo, форумные движки, форум...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\r\\nНа сегодняшний день процедура реализации ...</td>\n",
              "      <td>Кластер высокой доступности на postgresql 9.6 ...</td>\n",
              "      <td>\\r\\nНа сегодняшний день процедура реализации «...</td>\n",
              "      <td>https://habrahabr.ru/company/etagi/blog/314000/</td>\n",
              "      <td>[postgresq, haproxy, pgbouncer, keepalived, re...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Как часто, программируя очередную бизнес-фичу,...</td>\n",
              "      <td>Как перестать бояться и полюбить синтаксически...</td>\n",
              "      <td>Как часто, программируя очередную бизнес-фичу,...</td>\n",
              "      <td>https://habrahabr.ru/company/knopka/blog/314030/</td>\n",
              "      <td>[irony, .net, c#, грамматический разбор, синта...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Индустрия звука, о которая была у всех на слух...</td>\n",
              "      <td>Мифы и реальность: Что нужно знать о современн...</td>\n",
              "      <td>Индустрия звука, о которая была у всех на слух...</td>\n",
              "      <td>https://geektimes.ru/company/audiomania/blog/2...</td>\n",
              "      <td>[аудиомания, мифы и реальность, акустика, ауди...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ... abstract\n",
              "0   MassTransit это open source библиотека, разра...  ...      NaN\n",
              "1   Введение и выбор решения \\r\\nРано или поздно ...  ...      NaN\n",
              "2   \\r\\nНа сегодняшний день процедура реализации ...  ...      NaN\n",
              "3  Как часто, программируя очередную бизнес-фичу,...  ...      NaN\n",
              "4  Индустрия звука, о которая была у всех на слух...  ...      NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfeRYxOoK8Dp"
      },
      "source": [
        "def evaluate(true_kws, predicted_kws):\n",
        "    assert len(true_kws) == len(predicted_kws)\n",
        "    \n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1s = []\n",
        "    jaccards = []\n",
        "    \n",
        "    for i in range(len(true_kws)):\n",
        "        \n",
        "        true_kw = set(true_kws[i])\n",
        "        predicted_kw = set(predicted_kws[i])\n",
        "        \n",
        "        tp = len(true_kw & predicted_kw)\n",
        "        union = len(true_kw | predicted_kw)\n",
        "        fp = len(predicted_kw - true_kw)\n",
        "        fn = len(true_kw - predicted_kw)\n",
        "        \n",
        "        if (tp+fp) == 0:\n",
        "            prec = 0\n",
        "        else:\n",
        "            prec = tp / (tp + fp)\n",
        "        \n",
        "        if (tp+fn) == 0:\n",
        "            rec = 0\n",
        "        else:\n",
        "            rec = tp / (tp + fn)\n",
        "        if (prec+rec) == 0:\n",
        "            f1 = 0\n",
        "        else:\n",
        "            f1 = (2*(prec*rec))/(prec+rec)\n",
        "            \n",
        "        jac = tp / union\n",
        "        \n",
        "        precisions.append(prec)\n",
        "        recalls.append(rec)\n",
        "        f1s.append(f1)\n",
        "        jaccards.append(jac)\n",
        "    print('Precision - ', round(np.mean(precisions), 2))\n",
        "    print('Recall - ', round(np.mean(recalls), 2))\n",
        "    print('F1 - ', round(np.mean(f1s), 2))\n",
        "    print('Jaccard - ', round(np.mean(jaccards), 2))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahbhczLOLCU1",
        "outputId": "afd0c1e4-1641-42f5-897f-297fe8d43d6b"
      },
      "source": [
        "# to check that everything is ok\n",
        "evaluate(data['keywords'], data['keywords'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  1.0\n",
            "Recall -  1.0\n",
            "F1 -  1.0\n",
            "Jaccard -  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqWL43N3LSz6"
      },
      "source": [
        "# Baseline Solution "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-RiyKriLFVo"
      },
      "source": [
        "def normalize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
        "    words = [word.normal_form for word in words if word.tag.POS == 'NOUN']\n",
        "\n",
        "    return words"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_6dsTqSLhyI"
      },
      "source": [
        "data['content_norm'] = data['content'].apply(normalize)\n",
        "data['title_norm'] = data['title'].apply(normalize)\n",
        "data['content_norm_str'] = data['content_norm'].apply(' '.join)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzeV9bZMMzVS"
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
        "tfidf.fit(data['content_norm_str'])\n",
        "texts_vectors = tfidf.transform(data['content_norm_str'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsn5WVD4M-cI"
      },
      "source": [
        "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
        "keywords = []\n",
        "\n",
        "for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFeDw8jsNGoF",
        "outputId": "7e6f1b1e-5550-463c-b3b5-07a8165f139d"
      },
      "source": [
        "evaluate(data['keywords'], keywords)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.07\n",
            "Recall -  0.13\n",
            "F1 -  0.08\n",
            "Jaccard -  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Rlh9wD6YXv"
      },
      "source": [
        "# First Improvement - Normalization; "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2NXelsUhBOC"
      },
      "source": [
        "В выборке примеров можно заметить, что ключевыми словами могут быть в основном существительные и прилагательные. Попробуем добавить соответствующее условие в функцию нормализации. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pPeGZpsYvzb"
      },
      "source": [
        "def normalize(text):\n",
        "    \n",
        "    accepted_pos = ['NOUN', 'ADJF']\n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
        "    words = [word.normal_form for word in words if word.tag.POS in accepted_pos]\n",
        "\n",
        "    return words"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTxA75Enhctc"
      },
      "source": [
        "data['content_norm_v2'] = data['content'].apply(normalize)\n",
        "data['title_norm_v2'] = data['title'].apply(normalize)\n",
        "data['content_norm_str_v2'] = data['content_norm_v2'].apply(' '.join)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73czcJdOhuwm"
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
        "tfidf.fit(data['content_norm_str_v2'])\n",
        "texts_vectors = tfidf.transform(data['content_norm_str_v2'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXXRbbMlh592"
      },
      "source": [
        "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
        "keywords = []\n",
        "\n",
        "for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "husNfhu6h8eY",
        "outputId": "31b632aa-6f83-4256-c5f9-36f62a6d63c5"
      },
      "source": [
        "evaluate(data['keywords'], keywords)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.07\n",
            "Recall -  0.13\n",
            "F1 -  0.08\n",
            "Jaccard -  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxA2nz6PAx6L"
      },
      "source": [
        "Попробуем не фильтровать нормализацию в зависимости от частей речи, оставим все  части речи: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYR6KXo9BKID"
      },
      "source": [
        "def normalize(text):\n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
        "    words = [word.normal_form for word in words]\n",
        "    return words"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyfofyIlBK5k"
      },
      "source": [
        "data['content_norm_v3'] = data['content'].apply(normalize)\n",
        "data['title_norm_v3'] = data['title'].apply(normalize)\n",
        "data['content_norm_str_v3'] = data['content_norm_v3'].apply(' '.join)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9J01y3SBQdb"
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
        "tfidf.fit(data['content_norm_str_v3'])\n",
        "texts_vectors = tfidf.transform(data['content_norm_str_v3'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWsp_TS4BZOS"
      },
      "source": [
        "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
        "keywords = []\n",
        "\n",
        "for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ8_Wnwgtrho",
        "outputId": "c85b83fd-055e-4463-fe9c-5b191d6947cc"
      },
      "source": [
        "evaluate(data['keywords'], keywords)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.08\n",
            "Recall -  0.17\n",
            "F1 -  0.11\n",
            "Jaccard -  0.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H54xnMr9KVN"
      },
      "source": [
        "**Бейзлайн побит**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsca6oOb5iIY"
      },
      "source": [
        "И  попробуем сделать следующее: У нас есть набор ключевых слов, удалим все слова из набора, если они встречаются в словосочетаниях из этого набора. Например, ключевые слова: форум, инновации, технологический форум. Удалим \"форум\" т.к. он встречается в словосочетани \"технологический форум\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCppeDZ55aFh"
      },
      "source": [
        "import copy\n",
        "new_keywords = []\n",
        "\n",
        "for list_keywords in keywords:\n",
        "    to_new_keywords = []\n",
        "    for keyword in list_keywords:\n",
        "        _list_keywords = copy.deepcopy(list_keywords)\n",
        "        _list_keywords.remove(keyword)\n",
        "        presented = False\n",
        "        for _keyword in _list_keywords:\n",
        "            if keyword in _keyword:\n",
        "                presented = True\n",
        "        if presented is False:\n",
        "            to_new_keywords.append(keyword)\n",
        "    to_new_keywords = list(set(to_new_keywords))\n",
        "    new_keywords.append(to_new_keywords)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LefQFOx-65yQ",
        "outputId": "f55f6a6b-ee6a-4bf6-faf0-e0bd89571b5d"
      },
      "source": [
        "evaluate(data['keywords'], new_keywords)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.08\n",
            "Recall -  0.12\n",
            "F1 -  0.09\n",
            "Jaccard -  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekXHM_cjjZNm"
      },
      "source": [
        "# Second Imrovement - Concatenate Title + Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50bpYVGMjdUo"
      },
      "source": [
        "В названиях статей собирается выжимка всего текста. Попробуем учитывать также Title там где он есть. Используем при этом нормализацию бейзлайна, чтобы сравнить качество извлеченных ключевых слов именно с ним."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgZevsskquNp"
      },
      "source": [
        "data['title_norm_str'] = data['title_norm'].apply(' '.join)\n",
        "data['content_title'] = data['content_norm_str'] + data['title_norm_str']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JLqHq5h9hVr"
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
        "tfidf.fit(data['content_title'])\n",
        "texts_vectors = tfidf.transform(data['content_title'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KngZ5Ku-9r4L"
      },
      "source": [
        "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
        "keywords = []\n",
        "\n",
        "for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngIRLp-69wB0",
        "outputId": "8b0c00ed-70e4-42a2-8f13-f4ea7f8579ad"
      },
      "source": [
        "evaluate(data['keywords'], keywords)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.07\n",
            "Recall -  0.13\n",
            "F1 -  0.09\n",
            "Jaccard -  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfdGO8k2Ai-G"
      },
      "source": [
        "**Бейзлайн побит (F1 Score метрика))** Посмотрим также на результаты для v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU9BwTU2AjWD",
        "outputId": "b09d2da5-7e89-475b-babe-faaee56a7b88"
      },
      "source": [
        "data['title_norm_str_v3'] = data['title_norm_v3'].apply(' '.join)\n",
        "data['content_title_v3'] = data['content_norm_str_v3'] + data['title_norm_str_v3']\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
        "tfidf.fit(data['content_title_v3'])\n",
        "texts_vectors = tfidf.transform(data['content_title_v3'])\n",
        "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
        "keywords = []\n",
        "\n",
        "for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])\n",
        "evaluate(data['keywords'], keywords)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.09\n",
            "Recall -  0.17\n",
            "F1 -  0.11\n",
            "Jaccard -  0.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEV-b1w8DO2z"
      },
      "source": [
        "Тут улучшается Precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPKorfoph8-T"
      },
      "source": [
        "# Third Improvement - Exploring TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeyDKwBAjSMH"
      },
      "source": [
        "Попробуем покрутить параметры Tf-Idf векторайзера. Занизим параметр max_df, чтобы не учитывать самые встречаемые слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TGm1Fhsh-1x"
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=1, max_df=0.3)\n",
        "tfidf.fit(data['content_norm_str'])\n",
        "texts_vectors = tfidf.transform(data['content_norm_str'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zRfUN7fjY10"
      },
      "source": [
        "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
        "keywords = []\n",
        "\n",
        "for row in range(texts_vectors.shape[0]):\n",
        "    row_data = texts_vectors.getrow(row)\n",
        "    top_inds = row_data.toarray().argsort()[0,:-11:-1]\n",
        "    keywords.append([id2word[w] for w in top_inds])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfF_odj1AL4f",
        "outputId": "c8d230a3-ee65-4987-e05b-897572e768e9"
      },
      "source": [
        "evaluate(data['keywords'], keywords)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.07\n",
            "Recall -  0.13\n",
            "F1 -  0.08\n",
            "Jaccard -  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdDDGN9lCbhb"
      },
      "source": [
        "# Gensim "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfYAcp3-C-_g"
      },
      "source": [
        "_keywords =  data['content_norm_str'].apply(lambda x: summarization.keywords(x).split('\\n')[:10])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-uqrcfqDKLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e26430-4259-4698-f3f8-bf5bb59fd1ab"
      },
      "source": [
        "evaluate(data['keywords'], _keywords)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.03\n",
            "Recall -  0.05\n",
            "F1 -  0.03\n",
            "Jaccard -  0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIjCho5oDKeD"
      },
      "source": [
        "Совсем неудачный подход"
      ]
    }
  ]
}