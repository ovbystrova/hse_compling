{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3_spellchecker.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxa4IkJ1PtFobeGZJkiZbb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ovbystrova/hse_compling/blob/main/hw3/hw3_spellchecker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jVDQuxF_v-k"
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt -O data/sents_with_mistakes.txt\n",
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt -O data/correct_sents.txt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXp8saS2g1IY"
      },
      "source": [
        "%%capture \n",
        "!pip install razdel"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XPzl2whCdHt"
      },
      "source": [
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnM0wxBCCp89"
      },
      "source": [
        "punctuation += \"«»—…“”\"\n",
        "punct = set(punctuation)\n",
        "\n",
        "bad = open('data/sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
        "true = open('data/correct_sents.txt', encoding='utf8').read().splitlines()\n",
        "\n",
        "corpus = open('data/wiki_data.txt', encoding='utf8').read()\n",
        "vocab = set(re.findall('\\w+', corpus.lower()))\n",
        "\n",
        "WORDS = Counter(vocab) # Vocab\n",
        "N = sum(WORDS.values()) # Vocab length"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVoh0CiyBx_C"
      },
      "source": [
        "# Задание 1:\n",
        "\n",
        "Реализуйте алгоритм Symspell - https://medium.com/@wolfgarbe/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f. Он похож на алгоритм Норвига, но проще и быстрее. Там к словам в словаре применяется только одна операция - удаление символа. Чтобы найти исправление из слова тоже удаляются символы и сравниваются с теми, что хранятся в словаре. Оцените качество полученного алгоритма теми же тремя метриками."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvMQDZ6GCWHY",
        "outputId": "333155d2-93e2-4a8f-c237-62e0011e6766"
      },
      "source": [
        "bad[0], true[0], corpus[:50]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Симпатичнейшое шпионское устройство, такой себе гламурный фотоаппарат девушки Бонда - миниатюрная модель камеры Superheadz Clap Camera.',\n",
              " 'Симпатичнейшее шпионское устройство такой себе гламурный фотоаппарат девушки Бонда миниатюрная модель камеры Superheadz Clap Camera',\n",
              " '######Новостройка (Нижегородская область)#########')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYtz1dvkCXhX"
      },
      "source": [
        "def align_words(sent_1, sent_2):\n",
        "    tokens_1 = sent_1.lower().split()\n",
        "    tokens_2 = sent_2.lower().split()\n",
        "    \n",
        "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
        "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)] \n",
        "    return list(zip(tokens_1, tokens_2))\n",
        "\n",
        "def predict_mistaken(word, vocab):\n",
        "    return 0 if word in vocab else 1\n",
        "\n",
        "def P(word, N=N): \n",
        "    \"Вычисляем вероятность слова\"\n",
        "    return WORDS[word] / N"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygINg9WKoAr"
      },
      "source": [
        "def precompute_dictionary(vocab):\n",
        "    \"\"\"\n",
        "    Generate terms with an edit distance (deletes only) from each dictionary term \n",
        "    and add them together with the original term to the dictionary. \n",
        "    This has to be done only once during a pre-calculation step.\n",
        "    \"\"\"\n",
        "    dictionary = defaultdict(list)\n",
        "\n",
        "    for word in vocab:\n",
        "        deletions = edits1(word)\n",
        "        for reduced_form in deletions:\n",
        "            dictionary[reduced_form].append(word)\n",
        "    return dictionary\n",
        "\n",
        "def edits1(word):\n",
        "    \"Создаем кандидатов, которые отличаются на одну букву\"\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    return set(deletes)\n",
        "\n",
        "def find_candidates(term, dictionary):\n",
        "    \"\"\"\n",
        "    Generate terms with an edit distance (deletes only) from the input term \n",
        "    and search them in the dictionary.\n",
        "    \"\"\"\n",
        "    candidates = [term]\n",
        "    term_reduced = edits1(term)\n",
        "    candidates.extend(dictionary[term])\n",
        "    for reduced in term_reduced:\n",
        "        candidates.extend(dictionary[reduced])\n",
        "    return candidates\n",
        "\n",
        "def find_correction(word): \n",
        "    \"Находим наиболее вероятное похожее слово\"\n",
        "    candidates = find_candidates(word, dictionary=D)\n",
        "    return max(candidates, key=P)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tncbjvquMsJj"
      },
      "source": [
        "D = precompute_dictionary(WORDS)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXkAatyIMwRB",
        "outputId": "1f32292e-5067-43e6-da9f-08851b8eb0ba"
      },
      "source": [
        "D['солнц'], D['сонце'], D['лесница'], D['опофеоз']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['солнце', 'солнцу', 'солнца'], ['солнце'], ['лестница'], [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4yeK0VZO9k5",
        "outputId": "fc740aaf-dc84-42d9-913a-3b3ad4a7ba9f"
      },
      "source": [
        "find_candidates('сонце', dictionary=D)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['сонце',\n",
              " 'солнце',\n",
              " 'донце',\n",
              " 'конце',\n",
              " 'монце',\n",
              " 'соней',\n",
              " 'сионе',\n",
              " 'сонче',\n",
              " 'сонет',\n",
              " 'слоне',\n",
              " 'сосне',\n",
              " 'согне',\n",
              " 'сконе',\n",
              " 'сьоне',\n",
              " 'сотне']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57wr_dOhR4YT",
        "outputId": "264c2966-16ad-4277-a8a8-d27b67d05855"
      },
      "source": [
        "find_correction('сонце'), find_correction('соллнце'), find_correction('опофеоз')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('солнце', 'солнцем', 'апофеоз')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI6LpOWRTORy"
      },
      "source": [
        "def caltulate_metrics(true, bad):\n",
        "    \"\"\"\n",
        "    Для оценки используем будем использовать три метрики:\n",
        "    1) процент правильных слов;\n",
        "    2) процент исправленных ошибок\n",
        "    3) процент ошибочно исправленных правильных слов\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_mistaken = 0\n",
        "    mistaken_fixed = 0\n",
        "    total_correct = 0\n",
        "    correct_broken = 0\n",
        "\n",
        "    cashed = {}\n",
        "    for i in range(len(true)):\n",
        "        word_pairs = align_words(true[i], bad[i])\n",
        "        for pair in word_pairs:\n",
        "            if predict_mistaken(pair[1], WORDS):\n",
        "                predicted = cashed.get(pair[1], find_correction(pair[1]))\n",
        "            else:\n",
        "                predicted = pair[1]\n",
        "            # чтобы два раза не исправлять одно и тоже слово - закешируем его\n",
        "            # перед тем как считать исправление проверим нет ли его в кеше\n",
        "            cashed[pair[0]] = predicted       \n",
        "            if predicted == pair[0]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "            \n",
        "            if pair[0] == pair[1]:\n",
        "                total_correct += 1\n",
        "                if pair[0] !=  predicted:\n",
        "                    correct_broken += 1\n",
        "            else:\n",
        "                total_mistaken += 1\n",
        "                if pair[0] == predicted:\n",
        "                    mistaken_fixed += 1\n",
        "\n",
        "    print('Процент правильных слов: ', correct/total)\n",
        "    print('Процент исправленных ошибок: ', mistaken_fixed/total_mistaken)\n",
        "    print('Процент ошибочно исправленных правильных слов: ', correct_broken/total_correct)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHwpFS4wGASE",
        "outputId": "9d3a499a-89d4-4931-c3b8-aa3f082c4486"
      },
      "source": [
        "caltulate_metrics(true=true, bad=bad)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных слов:  0.8652347652347653\n",
            "Процент исправленных ошибок:  0.30775134305448965\n",
            "Процент ошибочно исправленных правильных слов:  0.0513380039049041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwxk5xu2jWNv"
      },
      "source": [
        "На данном этапе получилось исправить 30% ошибок, но зато мы меньше делаем исправления там где не надо (чем на семинаре). Что можно доработвать: сделать больше словарь, использовать более сложную функцию при выборе исправления из кандидатов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNOR13_nZFiJ"
      },
      "source": [
        "# Задание 2.\n",
        " Добавьте к полученному алгоритму исправления (Symspell) триграммную модель и проверьте, улучшает ли она качество. Триграммную модель нужно вставить туда, где у вас выбирается один из нескольких кандидатов на исправление."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igl-20GWUZDr"
      },
      "source": [
        "def preprocess(text):\n",
        "    sents = sentenize(text)\n",
        "    return [normalize(sent.text) for sent in sents]\n",
        "\n",
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text\n",
        "\n",
        "def ngrammer(tokens, n):\n",
        "    ngrams = []\n",
        "    tokens = [token for token in tokens]\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(tuple(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkOQRBuLZcxg"
      },
      "source": [
        "corpus_wiki = [['<start>', '<start>'] + sent + ['<end>'] for sent in preprocess(corpus)]\n",
        "\n",
        "unigrams = Counter()\n",
        "bigrams = Counter()\n",
        "trigrams = Counter()\n",
        "\n",
        "for sentence in corpus_wiki:\n",
        "    unigrams.update(sentence)\n",
        "    bigrams.update(ngrammer(sentence, 2))\n",
        "    trigrams.update(ngrammer(sentence, 3))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNZByB_ckDkv"
      },
      "source": [
        "def calculate_metrics_with_trigramms(true, bad, WORDS=WORDS, D=D, \n",
        "                                     bigrams=bigrams, trigrams=trigrams):\n",
        "    \"\"\"\n",
        "    Для оценки используем будем использовать три метрики:\n",
        "    1) процент правильных слов;\n",
        "    2) процент исправленных ошибок\n",
        "    3) процент ошибочно исправленных правильных слов\n",
        "    \"\"\"\n",
        "    mistakes = []\n",
        "    total_mistaken = 0\n",
        "    mistaken_fixed = 0\n",
        "    total_correct = 0\n",
        "    correct_broken = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(len(true)):\n",
        "        word_pairs = align_words(true[i], bad[i])  \n",
        "        word_pairs = [('<start>', '<start>')] + word_pairs\n",
        "        pred_sent = []\n",
        "        for j in range(2, len(word_pairs)):       \n",
        "            pred = None       \n",
        "            if not predict_mistaken(word_pairs[j][1], WORDS):\n",
        "                pred = word_pairs[j][1]    \n",
        "            else:\n",
        "                predicted = find_candidates(word_pairs[j][1], dictionary=D)\n",
        "                prev_word = word_pairs[j-2][1] + ' ' + word_pairs[j-1][1]    \n",
        "                if prev_word not in bigrams:\n",
        "                    pred = max(predicted, key=P)\n",
        "                else:\n",
        "                    lm_predicted = []\n",
        "                    for word in predicted:\n",
        "                        trigram = ' '.join([prev_word, word])\n",
        "                        lm_predicted.append((word, ((trigrams[trigram]/bigrams[prev_word]))))               \n",
        "                    if lm_predicted:\n",
        "                        pred = sorted(lm_predicted, key=lambda x: -x[1])[0][0]\n",
        "            if pred is None:\n",
        "                pred = word_pairs[j][1] \n",
        "            if pred == word_pairs[j][0]:\n",
        "                correct += 1\n",
        "            else:\n",
        "                mistakes.append((word_pairs[j][0], word_pairs[j][1], pred))\n",
        "            total += 1        \n",
        "            if word_pairs[j][0] == word_pairs[j][1]:\n",
        "                total_correct += 1\n",
        "                if word_pairs[j][0] !=  pred:\n",
        "                    correct_broken += 1\n",
        "            else:\n",
        "                total_mistaken += 1\n",
        "                if word_pairs[j][0] == pred:\n",
        "                    mistaken_fixed += 1\n",
        "    print('Процент правильных слов: ', correct/total)\n",
        "    print('Процент исправленных ошибок: ', mistaken_fixed/total_mistaken)\n",
        "    print('Процент ошибочно исправленных правильных слов: ', correct_broken/total_correct)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDWQP20ikwC_",
        "outputId": "4abf6137-035b-409c-8b74-90c5aeb3f5e7"
      },
      "source": [
        "calculate_metrics_with_trigramms(true, bad)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных слов:  0.890367275126457\n",
            "Процент исправленных ошибок:  0.21610738255033557\n",
            "Процент ошибочно исправленных правильных слов:  0.049467002036172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AldSzYAXljVN"
      },
      "source": [
        " Еще немного уменьшился процент ошибочно исправленных правильных слов, но вместе с ним и упал процент исправленных ошибок. В качестве возможных улучшений сюда можно отнести пополнение словаря/корпуса. "
      ]
    }
  ]
}